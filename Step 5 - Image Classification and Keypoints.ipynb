{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e91c0a12",
   "metadata": {},
   "source": [
    "# Basic Setup and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f1a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch to build a convolutional neural network\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy, Precision, F1Score\n",
    "\n",
    "import itertools\n",
    "# from pyimagesearch import config\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eba33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPUs if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02376bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to the flowers and mnist dataset\n",
    "CURRENT_DATASET_PATH = \"dataset-for-classification\"\n",
    "# FINAL_DATASET_PATH = \"dataset-final\"\n",
    "# # specify the paths to our training and validation set \n",
    "# TRAIN = \"train\"\n",
    "# VAL = \"val\"\n",
    "# # set the input height and width\n",
    "# INPUT_HEIGHT = 128\n",
    "# INPUT_WIDTH = 128\n",
    "# # set the batch size and validation data split\n",
    "# BATCH_SIZE = 8\n",
    "# VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214e2d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nose_scaled_x</th>\n",
       "      <th>nose_scaled_y</th>\n",
       "      <th>nose_score</th>\n",
       "      <th>left_eye_scaled_x</th>\n",
       "      <th>left_eye_scaled_y</th>\n",
       "      <th>left_eye_score</th>\n",
       "      <th>right_eye_scaled_x</th>\n",
       "      <th>right_eye_scaled_y</th>\n",
       "      <th>right_eye_score</th>\n",
       "      <th>left_ear_scaled_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_knee_scaled_x</th>\n",
       "      <th>right_knee_scaled_y</th>\n",
       "      <th>right_knee_score</th>\n",
       "      <th>left_ankle_scaled_x</th>\n",
       "      <th>left_ankle_scaled_y</th>\n",
       "      <th>left_ankle_score</th>\n",
       "      <th>right_ankle_scaled_x</th>\n",
       "      <th>right_ankle_scaled_y</th>\n",
       "      <th>right_ankle_score</th>\n",
       "      <th>pose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/paripurna-navasana/7ef89ad4433e9e5af2218d2c870845a44f994b18a123852e79c585f77bdc1488.png</th>\n",
       "      <td>0.558346</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>1.949889</td>\n",
       "      <td>0.540620</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>1.943505</td>\n",
       "      <td>0.512555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.750488</td>\n",
       "      <td>0.304284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985229</td>\n",
       "      <td>0.465092</td>\n",
       "      <td>0.057829</td>\n",
       "      <td>0.995569</td>\n",
       "      <td>0.407598</td>\n",
       "      <td>0.091656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407598</td>\n",
       "      <td>0.083489</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/padmasana/2ba9fd144da5dee7636bac100b1961875f69e66e0e4007ceba31ea32d40ff0b5.jpeg</th>\n",
       "      <td>0.491987</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.857787</td>\n",
       "      <td>0.540064</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>1.265977</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.498770</td>\n",
       "      <td>0.599359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.983103</td>\n",
       "      <td>0.143049</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.955453</td>\n",
       "      <td>0.138958</td>\n",
       "      <td>0.330128</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/upavistha-konasana/105c894c324470bffd7517867d5ac97db8dd8765bd787b0c4b36f1aadf069c1e.png</th>\n",
       "      <td>0.596422</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.972064</td>\n",
       "      <td>0.638171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.963699</td>\n",
       "      <td>0.554672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.430774</td>\n",
       "      <td>0.681909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>0.675944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>0.047240</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/marjaryasana/8dc6474628fdf057f89bc360f1275070ae7bf5b4b17433c50543e663ee26680a.png</th>\n",
       "      <td>0.972571</td>\n",
       "      <td>0.205837</td>\n",
       "      <td>0.270333</td>\n",
       "      <td>0.989714</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>0.216276</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.168971</td>\n",
       "      <td>0.173521</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366857</td>\n",
       "      <td>0.304147</td>\n",
       "      <td>0.328321</td>\n",
       "      <td>0.413714</td>\n",
       "      <td>0.960061</td>\n",
       "      <td>0.116407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.906298</td>\n",
       "      <td>0.208869</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/urdhva-prasarita-eka-padasana/157976074d7a676da7623d971725c399ec46656350936d278bf46eb09a775475.png</th>\n",
       "      <td>0.568889</td>\n",
       "      <td>0.785776</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>0.724444</td>\n",
       "      <td>0.822203</td>\n",
       "      <td>0.106847</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.821336</td>\n",
       "      <td>0.153943</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202082</td>\n",
       "      <td>0.167313</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.884649</td>\n",
       "      <td>0.429937</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297149</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/adho-mukha-vrksasana/e160e25b7e8bea91a6f1d5cf4914a667a5f9b03bc12bbe791fe3ab7d569cfe14.png</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787596</td>\n",
       "      <td>0.249642</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>0.751062</td>\n",
       "      <td>0.069631</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>0.751912</td>\n",
       "      <td>0.249675</td>\n",
       "      <td>0.116564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.225149</td>\n",
       "      <td>0.167277</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087273</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144229</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/chaturanga-dandasana/ced03afa1c06fb3cd419e700dbe7357c83ca0b9d28785d240ab5a0e4024633df.png</th>\n",
       "      <td>0.535976</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.193930</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.483108</td>\n",
       "      <td>0.220233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290541</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.493392</td>\n",
       "      <td>0.956081</td>\n",
       "      <td>0.162056</td>\n",
       "      <td>0.490455</td>\n",
       "      <td>0.969595</td>\n",
       "      <td>0.166776</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/utthita-parsvakonasana/194d700849c2954d3fa3135214fb5fc5c843836cdeba24a804f880ec477746da.png</th>\n",
       "      <td>0.142606</td>\n",
       "      <td>0.252717</td>\n",
       "      <td>0.332290</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.240489</td>\n",
       "      <td>0.207598</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.240489</td>\n",
       "      <td>0.511607</td>\n",
       "      <td>0.061620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.650815</td>\n",
       "      <td>0.174187</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.998641</td>\n",
       "      <td>0.279461</td>\n",
       "      <td>0.058099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481291</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/supta-baddha-konasana/e06ef7b69d0c200b15de610cec58147925918eca05ba9c65966901aadcbccef8.png</th>\n",
       "      <td>0.046092</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.932778</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>0.060325</td>\n",
       "      <td>0.471865</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>0.125290</td>\n",
       "      <td>0.693817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656613</td>\n",
       "      <td>0.180462</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.631090</td>\n",
       "      <td>0.305968</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./dataset-for-classification/baddha-konasana/12ca2a1d6b43266b5bd3c8a4a8229d3ee34067d23bd4ae3c9a9106b034c2401b.png</th>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.132428</td>\n",
       "      <td>1.364339</td>\n",
       "      <td>0.877828</td>\n",
       "      <td>0.086587</td>\n",
       "      <td>2.059145</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.084890</td>\n",
       "      <td>2.218163</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747029</td>\n",
       "      <td>0.411823</td>\n",
       "      <td>0.402715</td>\n",
       "      <td>0.920204</td>\n",
       "      <td>0.076261</td>\n",
       "      <td>0.520362</td>\n",
       "      <td>0.933786</td>\n",
       "      <td>0.069572</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3313 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    nose_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...       0.558346   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...       0.491987   \n",
       "./dataset-for-classification/upavistha-konasana...       0.596422   \n",
       "./dataset-for-classification/marjaryasana/8dc64...       0.972571   \n",
       "./dataset-for-classification/urdhva-prasarita-e...       0.568889   \n",
       "...                                                           ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...       1.000000   \n",
       "./dataset-for-classification/chaturanga-dandasa...       0.535976   \n",
       "./dataset-for-classification/utthita-parsvakona...       0.142606   \n",
       "./dataset-for-classification/supta-baddha-konas...       0.046092   \n",
       "./dataset-for-classification/baddha-konasana/12...       0.809955   \n",
       "\n",
       "                                                    nose_scaled_y  nose_score  \\\n",
       "./dataset-for-classification/paripurna-navasana...       0.041068    1.949889   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...       0.032258    1.857787   \n",
       "./dataset-for-classification/upavistha-konasana...       0.031532    0.972064   \n",
       "./dataset-for-classification/marjaryasana/8dc64...       0.205837    0.270333   \n",
       "./dataset-for-classification/urdhva-prasarita-e...       0.785776    0.601770   \n",
       "...                                                           ...         ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...       0.787596    0.249642   \n",
       "./dataset-for-classification/chaturanga-dandasa...       0.797297    0.193930   \n",
       "./dataset-for-classification/utthita-parsvakona...       0.252717    0.332290   \n",
       "./dataset-for-classification/supta-baddha-konas...       0.067285    0.932778   \n",
       "./dataset-for-classification/baddha-konasana/12...       0.132428    1.364339   \n",
       "\n",
       "                                                    left_eye_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...           0.540620   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...           0.540064   \n",
       "./dataset-for-classification/upavistha-konasana...           0.638171   \n",
       "./dataset-for-classification/marjaryasana/8dc64...           0.989714   \n",
       "./dataset-for-classification/urdhva-prasarita-e...           0.724444   \n",
       "...                                                               ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...           0.723926   \n",
       "./dataset-for-classification/chaturanga-dandasa...           0.007342   \n",
       "./dataset-for-classification/utthita-parsvakona...           0.147887   \n",
       "./dataset-for-classification/supta-baddha-konas...           0.025050   \n",
       "./dataset-for-classification/baddha-konasana/12...           0.877828   \n",
       "\n",
       "                                                    left_eye_scaled_y  \\\n",
       "./dataset-for-classification/paripurna-navasana...           0.001027   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...           0.001536   \n",
       "./dataset-for-classification/upavistha-konasana...           0.000000   \n",
       "./dataset-for-classification/marjaryasana/8dc64...           0.168971   \n",
       "./dataset-for-classification/urdhva-prasarita-e...           0.822203   \n",
       "...                                                               ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...           0.751062   \n",
       "./dataset-for-classification/chaturanga-dandasa...           0.483108   \n",
       "./dataset-for-classification/utthita-parsvakona...           0.240489   \n",
       "./dataset-for-classification/supta-baddha-konas...           0.060325   \n",
       "./dataset-for-classification/baddha-konasana/12...           0.086587   \n",
       "\n",
       "                                                    left_eye_score  \\\n",
       "./dataset-for-classification/paripurna-navasana...        1.943505   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...        1.265977   \n",
       "./dataset-for-classification/upavistha-konasana...        1.963699   \n",
       "./dataset-for-classification/marjaryasana/8dc64...        0.216276   \n",
       "./dataset-for-classification/urdhva-prasarita-e...        0.106847   \n",
       "...                                                            ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...        0.069631   \n",
       "./dataset-for-classification/chaturanga-dandasa...        0.220233   \n",
       "./dataset-for-classification/utthita-parsvakona...        0.207598   \n",
       "./dataset-for-classification/supta-baddha-konas...        0.471865   \n",
       "./dataset-for-classification/baddha-konasana/12...        2.059145   \n",
       "\n",
       "                                                    right_eye_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...            0.512555   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...            0.448718   \n",
       "./dataset-for-classification/upavistha-konasana...            0.554672   \n",
       "./dataset-for-classification/marjaryasana/8dc64...            0.965714   \n",
       "./dataset-for-classification/urdhva-prasarita-e...            0.760000   \n",
       "...                                                                ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...            0.797546   \n",
       "./dataset-for-classification/chaturanga-dandasa...            0.000000   \n",
       "./dataset-for-classification/utthita-parsvakona...            0.077465   \n",
       "./dataset-for-classification/supta-baddha-konas...            0.011022   \n",
       "./dataset-for-classification/baddha-konasana/12...            0.748869   \n",
       "\n",
       "                                                    right_eye_scaled_y  \\\n",
       "./dataset-for-classification/paripurna-navasana...            0.000000   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...            0.000000   \n",
       "./dataset-for-classification/upavistha-konasana...            0.000000   \n",
       "./dataset-for-classification/marjaryasana/8dc64...            0.168971   \n",
       "./dataset-for-classification/urdhva-prasarita-e...            0.821336   \n",
       "...                                                                ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...            0.751912   \n",
       "./dataset-for-classification/chaturanga-dandasa...            0.479730   \n",
       "./dataset-for-classification/utthita-parsvakona...            0.240489   \n",
       "./dataset-for-classification/supta-baddha-konas...            0.125290   \n",
       "./dataset-for-classification/baddha-konasana/12...            0.084890   \n",
       "\n",
       "                                                    right_eye_score  \\\n",
       "./dataset-for-classification/paripurna-navasana...         2.750488   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...         1.498770   \n",
       "./dataset-for-classification/upavistha-konasana...         4.430774   \n",
       "./dataset-for-classification/marjaryasana/8dc64...         0.173521   \n",
       "./dataset-for-classification/urdhva-prasarita-e...         0.153943   \n",
       "...                                                             ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...         0.249675   \n",
       "./dataset-for-classification/chaturanga-dandasa...         0.024991   \n",
       "./dataset-for-classification/utthita-parsvakona...         0.511607   \n",
       "./dataset-for-classification/supta-baddha-konas...         0.693817   \n",
       "./dataset-for-classification/baddha-konasana/12...         2.218163   \n",
       "\n",
       "                                                    left_ear_scaled_x  ...  \\\n",
       "./dataset-for-classification/paripurna-navasana...           0.304284  ...   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...           0.599359  ...   \n",
       "./dataset-for-classification/upavistha-konasana...           0.681909  ...   \n",
       "./dataset-for-classification/marjaryasana/8dc64...           0.942857  ...   \n",
       "./dataset-for-classification/urdhva-prasarita-e...           0.826667  ...   \n",
       "...                                                               ...  ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...           0.116564  ...   \n",
       "./dataset-for-classification/chaturanga-dandasa...           0.024963  ...   \n",
       "./dataset-for-classification/utthita-parsvakona...           0.061620  ...   \n",
       "./dataset-for-classification/supta-baddha-konas...           0.000000  ...   \n",
       "./dataset-for-classification/baddha-konasana/12...           0.941176  ...   \n",
       "\n",
       "                                                    right_knee_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...             0.985229   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...             0.067308   \n",
       "./dataset-for-classification/upavistha-konasana...             0.053678   \n",
       "./dataset-for-classification/marjaryasana/8dc64...             0.366857   \n",
       "./dataset-for-classification/urdhva-prasarita-e...             0.000000   \n",
       "...                                                                 ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...             0.564417   \n",
       "./dataset-for-classification/chaturanga-dandasa...             1.000000   \n",
       "./dataset-for-classification/utthita-parsvakona...             0.105634   \n",
       "./dataset-for-classification/supta-baddha-konas...             0.986974   \n",
       "./dataset-for-classification/baddha-konasana/12...             0.000000   \n",
       "\n",
       "                                                    right_knee_scaled_y  \\\n",
       "./dataset-for-classification/paripurna-navasana...             0.465092   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...             0.983103   \n",
       "./dataset-for-classification/upavistha-konasana...             1.000000   \n",
       "./dataset-for-classification/marjaryasana/8dc64...             0.304147   \n",
       "./dataset-for-classification/urdhva-prasarita-e...             0.202082   \n",
       "...                                                                 ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...             0.225149   \n",
       "./dataset-for-classification/chaturanga-dandasa...             0.290541   \n",
       "./dataset-for-classification/utthita-parsvakona...             0.650815   \n",
       "./dataset-for-classification/supta-baddha-konas...             0.000000   \n",
       "./dataset-for-classification/baddha-konasana/12...             0.747029   \n",
       "\n",
       "                                                    right_knee_score  \\\n",
       "./dataset-for-classification/paripurna-navasana...          0.057829   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...          0.143049   \n",
       "./dataset-for-classification/upavistha-konasana...          0.042947   \n",
       "./dataset-for-classification/marjaryasana/8dc64...          0.328321   \n",
       "./dataset-for-classification/urdhva-prasarita-e...          0.167313   \n",
       "...                                                              ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...          0.167277   \n",
       "./dataset-for-classification/chaturanga-dandasa...          0.029234   \n",
       "./dataset-for-classification/utthita-parsvakona...          0.174187   \n",
       "./dataset-for-classification/supta-baddha-konas...          0.242699   \n",
       "./dataset-for-classification/baddha-konasana/12...          0.411823   \n",
       "\n",
       "                                                    left_ankle_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...             0.995569   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...             0.474359   \n",
       "./dataset-for-classification/upavistha-konasana...             0.675944   \n",
       "./dataset-for-classification/marjaryasana/8dc64...             0.413714   \n",
       "./dataset-for-classification/urdhva-prasarita-e...             0.053333   \n",
       "...                                                                 ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...             0.570552   \n",
       "./dataset-for-classification/chaturanga-dandasa...             0.493392   \n",
       "./dataset-for-classification/utthita-parsvakona...             0.063380   \n",
       "./dataset-for-classification/supta-baddha-konas...             1.000000   \n",
       "./dataset-for-classification/baddha-konasana/12...             0.402715   \n",
       "\n",
       "                                                    left_ankle_scaled_y  \\\n",
       "./dataset-for-classification/paripurna-navasana...             0.407598   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...             0.955453   \n",
       "./dataset-for-classification/upavistha-konasana...             1.000000   \n",
       "./dataset-for-classification/marjaryasana/8dc64...             0.960061   \n",
       "./dataset-for-classification/urdhva-prasarita-e...             0.884649   \n",
       "...                                                                 ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...             1.000000   \n",
       "./dataset-for-classification/chaturanga-dandasa...             0.956081   \n",
       "./dataset-for-classification/utthita-parsvakona...             0.998641   \n",
       "./dataset-for-classification/supta-baddha-konas...             0.656613   \n",
       "./dataset-for-classification/baddha-konasana/12...             0.920204   \n",
       "\n",
       "                                                    left_ankle_score  \\\n",
       "./dataset-for-classification/paripurna-navasana...          0.091656   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...          0.138958   \n",
       "./dataset-for-classification/upavistha-konasana...          0.078737   \n",
       "./dataset-for-classification/marjaryasana/8dc64...          0.116407   \n",
       "./dataset-for-classification/urdhva-prasarita-e...          0.429937   \n",
       "...                                                              ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...          0.087273   \n",
       "./dataset-for-classification/chaturanga-dandasa...          0.162056   \n",
       "./dataset-for-classification/utthita-parsvakona...          0.279461   \n",
       "./dataset-for-classification/supta-baddha-konas...          0.180462   \n",
       "./dataset-for-classification/baddha-konasana/12...          0.076261   \n",
       "\n",
       "                                                    right_ankle_scaled_x  \\\n",
       "./dataset-for-classification/paripurna-navasana...              1.000000   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...              0.330128   \n",
       "./dataset-for-classification/upavistha-konasana...              0.000000   \n",
       "./dataset-for-classification/marjaryasana/8dc64...              0.000000   \n",
       "./dataset-for-classification/urdhva-prasarita-e...              0.035556   \n",
       "...                                                                  ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...              0.404908   \n",
       "./dataset-for-classification/chaturanga-dandasa...              0.490455   \n",
       "./dataset-for-classification/utthita-parsvakona...              0.058099   \n",
       "./dataset-for-classification/supta-baddha-konas...              0.995992   \n",
       "./dataset-for-classification/baddha-konasana/12...              0.520362   \n",
       "\n",
       "                                                    right_ankle_scaled_y  \\\n",
       "./dataset-for-classification/paripurna-navasana...              0.407598   \n",
       "./dataset-for-classification/padmasana/2ba9fd14...              0.826421   \n",
       "./dataset-for-classification/upavistha-konasana...              0.898649   \n",
       "./dataset-for-classification/marjaryasana/8dc64...              0.906298   \n",
       "./dataset-for-classification/urdhva-prasarita-e...              0.000000   \n",
       "...                                                                  ...   \n",
       "./dataset-for-classification/adho-mukha-vrksasa...              0.000000   \n",
       "./dataset-for-classification/chaturanga-dandasa...              0.969595   \n",
       "./dataset-for-classification/utthita-parsvakona...              1.000000   \n",
       "./dataset-for-classification/supta-baddha-konas...              0.631090   \n",
       "./dataset-for-classification/baddha-konasana/12...              0.933786   \n",
       "\n",
       "                                                    right_ankle_score  pose  \n",
       "./dataset-for-classification/paripurna-navasana...           0.083489    38  \n",
       "./dataset-for-classification/padmasana/2ba9fd14...           0.221899    37  \n",
       "./dataset-for-classification/upavistha-konasana...           0.047240    60  \n",
       "./dataset-for-classification/marjaryasana/8dc64...           0.208869    33  \n",
       "./dataset-for-classification/urdhva-prasarita-e...           0.297149    63  \n",
       "...                                                               ...   ...  \n",
       "./dataset-for-classification/adho-mukha-vrksasa...           0.144229     2  \n",
       "./dataset-for-classification/chaturanga-dandasa...           0.166776    19  \n",
       "./dataset-for-classification/utthita-parsvakona...           0.481291    70  \n",
       "./dataset-for-classification/supta-baddha-konas...           0.305968    53  \n",
       "./dataset-for-classification/baddha-konasana/12...           0.069572    10  \n",
       "\n",
       "[3313 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the dataset\n",
    "df = pd.read_csv('training_set.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bd0647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['pose'].unique()\n",
    "len(classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d973036d",
   "metadata": {},
   "source": [
    "# Building a Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f57da465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('dataset-annotations.csv', header=False)\n",
    "# df.sample(5).to_csv('dataset-annotations-head.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea296dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'adho-mukha-svanasana',\n",
    "    'adho-mukha-vriksasana',\n",
    "    'adho-mukha-vrksasana',\n",
    "    'ananda-balasana',\n",
    "    'anjaneyasana',\n",
    "    'ardha-chandrasana',\n",
    "    'ardha-matsyendrasana',\n",
    "    'ardha-pincha-mayurasana',\n",
    "    'ardha-uttanasana',\n",
    "    'astavakrasana',\n",
    "    'baddha-konasana',\n",
    "    'bakasana',\n",
    "    'balasana',\n",
    "    'bharadvajasana-i',\n",
    "    'bhujangasana',\n",
    "    'bhujapidasana',\n",
    "    'bitilasana',\n",
    "    'camatkarasana',\n",
    "    'chakravakasana',\n",
    "    'chaturanga-dandasana',\n",
    "    'dandasana',\n",
    "    'dhanurasana',\n",
    "    'dwi-pada-viparita-dandasana',\n",
    "    'eka-pada-koundinyanasana-i',\n",
    "    'eka-pada-koundinyanasana-ii',\n",
    "    'eka-pada-rajakapotasana',\n",
    "    'eka-pada-rajakapotasana-ii',\n",
    "    'garudasana',\n",
    "    'gomukhasana',\n",
    "    'halasana',\n",
    "    'kapotasana',\n",
    "    'makarasana',\n",
    "    'malasana',\n",
    "    'marjaryasana',\n",
    "    'matsyasana',\n",
    "    'mayurasana',\n",
    "    'natarajasana',\n",
    "    'padmasana',\n",
    "    'paripurna-navasana',\n",
    "    'parivrtta-trikonasana',\n",
    "    'parsva-bakasana',\n",
    "    'pasasana',\n",
    "    'paschimottanasana',\n",
    "    'phalakasana',\n",
    "    'prasarita-padottanasana',\n",
    "    'purvottanasana',\n",
    "    'salabhasana',\n",
    "    'salamba-bhujangasana',\n",
    "    'salamba-sarvangasana',\n",
    "    'salamba-sirsasana',\n",
    "    'savasana',\n",
    "    'setu-bandha-sarvangasana',\n",
    "    'sukhasana',\n",
    "    'supta-baddha-konasana',\n",
    "    'supta-matsyendrasana',\n",
    "    'supta-padangusthasana',\n",
    "    'supta-virasana',\n",
    "    'tadasana',\n",
    "    'tittibhasana',\n",
    "    'tolasana',\n",
    "    'upavistha-konasana',\n",
    "    'urdhva-dhanurasana',\n",
    "    'urdhva-mukha-svanasana',\n",
    "    'urdhva-prasarita-eka-padasana',\n",
    "    'ustrasana',\n",
    "    'utkatasana',\n",
    "    'uttana-shishosana',\n",
    "    'uttanasana',\n",
    "    'utthita-hasta-padangustasana',\n",
    "    'utthita-hasta-padangusthasana',\n",
    "    'utthita-parsvakonasana',\n",
    "    'utthita-trikonasana',\n",
    "    'vajrasana',\n",
    "    'vasisthasana',\n",
    "    'viparita-karani',\n",
    "    'virabhadrasana-i',\n",
    "    'virabhadrasana-ii',\n",
    "    'virabhadrasana-iii',\n",
    "    'virasana',\n",
    "    'vriksasana',\n",
    "    'vrischikasana',\n",
    "    'vrksasana'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d8adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "class CollectionsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, num_classes, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_file, index_col=0, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data.index[idx])\n",
    "        # img_name = os.path.join(self.root_dir, self.data.index[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        # TODO: resizing and whatnot?\n",
    "        pose = self.data.iloc[idx, -1]\n",
    "        # labels = labels.split()\n",
    "\n",
    "        pose_tensor = torch.zeros(self.num_classes)\n",
    "        pose_tensor[int(pose)] = 1\n",
    "        # pose_tensor = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "        dataframe = self.data.iloc[idx, :-1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, pose_tensor\n",
    "            # {\n",
    "            # 'image': image,\n",
    "            # 'pose': pose_tensor,\n",
    "            # 'keypoints': dataframe\n",
    "            # }\n",
    "    \n",
    "\n",
    "transformer = torchvision.transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize(size = (224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.PILToTensor()\n",
    "])\n",
    "target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "\n",
    "# create the dataset\n",
    "dataset = CollectionsDataset(csv_file='training_set.csv', root_dir=CURRENT_DATASET_PATH, num_classes=len(classes), transform=transformer)\n",
    "# dataset = CollectionsDataset(csv_file='dataset-annotations-head.csv', root_dir=CURRENT_DATASET_PATH, num_classes=len(classes), transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50bd2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba65cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26ce83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1816e5610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39be37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 224, 224])\n",
      "Labels batch shape: torch.Size([64, 82])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274b9bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: utthita-hasta-padangusthasana\n"
     ]
    }
   ],
   "source": [
    "img = train_features[0]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "label = torch.argmax(label)\n",
    "plt.show()\n",
    "print(f\"Label: {classes[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9eb77a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from here - https://www.kaggle.com/code/elinteerie/yoga-posture-acc-93-f1score-92-8\n",
    "# import torch.utils.data as data\n",
    "\n",
    "# # Random split\n",
    "# train_set_size = int(len(datafolder) * 0.8)\n",
    "# valid_set_size = len(datafolder) - train_set_size\n",
    "# train_set, valid_set = data.random_split(datafolder, [train_set_size, valid_set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67baf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.models.efficientnet as e\n",
    "import torchvision.models.resnet as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c50ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dubplate/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dubplate/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/dubplate/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS = r.resnet50(pretrained=True)\n",
    "WEIGHTS2 = e.efficientnet_b0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d76e76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YogaNet(nn.Module):\n",
    "    def __init__(self, base_model, additional_dims, num_classes=82):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        for p in self.base_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # self.kpts = nn.Sequential(\n",
    "        #     nn.Linear(additional_dims, additional_dims*4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(additional_dims*4, additional_dims*2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(additional_dims*2, additional_dims)\n",
    "        # )\n",
    "\n",
    "        # self.base_model.fc = nn.Linear(2048 + additional_dims, num_classes)\n",
    "        self.base_model.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = F.relu(self.base_model(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # output = self.fc3(x)\n",
    "\n",
    "        output = F.relu(self.base_model(x))\n",
    "\n",
    "\n",
    "        if self.training is not True:\n",
    "            output = self.softmax_layer(x)\n",
    "\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aee77f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YogaNet(WEIGHTS, additional_dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f9501fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of YogaNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=82, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b43a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTS.fc = nn.Sequential(\n",
    "#     nn.Linear(2048, 128),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(128, len(classes))\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e15212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# BATCH_SIZE = 32\n",
    "# train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e0bb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "# change WEIGHTS to model\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.01)\n",
    "accuracy_fn = Accuracy(task='multiclass', num_classes=len(classes)).to(device)\n",
    "f1 = F1Score(task='multiclass', num_classes=len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d5b7e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82])\n",
      "torch.Size([64, 82])\n",
      "-----------\n",
      "tensor([[0.3446, 0.2977, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0323, 0.1436, 0.2204,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3520, 0.3468, 0.0672,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.3997, 0.3800, 0.1048,  ..., 0.0000, 0.0000, 0.0048],\n",
      "        [0.3549, 0.0000, 0.1718,  ..., 0.0659, 0.0000, 0.0000],\n",
      "        [0.3306, 0.3409, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(y)\n\u001b[1;32m     19\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[0;32m---> 20\u001b[0m train_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy_fn(y_pred\u001b[39m.\u001b[39;49margmax(dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), y)\n\u001b[1;32m     21\u001b[0m train_losses \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     22\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchmetrics/metric.py:236\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_reduce_state_update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchmetrics/metric.py:302\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    303\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[1;32m    305\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchmetrics/metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    391\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    392\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchmetrics/classification/stat_scores.py:315\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 315\u001b[0m     _multiclass_stat_scores_tensor_validation(\n\u001b[1;32m    316\u001b[0m         preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultidim_average, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index\n\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    318\u001b[0m preds, target \u001b[39m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k)\n\u001b[1;32m    319\u001b[0m tp, fp, tn, fn \u001b[39m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    320\u001b[0m     preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maverage, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultidim_average, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index\n\u001b[1;32m    321\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/capstone/lib/python3.8/site-packages/torchmetrics/functional/classification/stat_scores.py:298\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    294\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWhen `preds` and `target` have the same shape, the shape of `preds` should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m atleast 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m and `preds` should be (N, C, ...).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    303\u001b[0m num_unique_values \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(torch\u001b[39m.\u001b[39munique(target))\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m ignore_index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...)."
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "train_losses, train_acc = 0, 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for batch, (X, y)in enumerate(train_dataloader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    # should change WEIGHTS to model\n",
    "    model.train()\n",
    "\n",
    "    # should change model to model\n",
    "    y_pred = model(X)\n",
    "    print(y_pred.shape)\n",
    "    print(y.shape)\n",
    "    print('-----------')\n",
    "    print(y_pred)\n",
    "    print(y)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_acc += accuracy_fn(y_pred.argmax(dim=1), y)\n",
    "    train_losses += loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch % 100 == 0:\n",
    "      print(f'{train_losses} | {train_acc}')\n",
    "\n",
    "  train_losses /= len(train_dataloader)\n",
    "  train_acc /= len(train_dataloader)\n",
    "  print(f' Train Loss: {train_losses:.4f} | Train Acc: {train_acc:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8d9c436",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d45f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb44351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2acac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49e832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2280a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8627e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066d6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "350fda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # row = self.df.iloc[idx]\n",
    "        # X = torch.tensor(row.drop(['pose']).values, dtype=torch.float)\n",
    "        # y = torch.tensor(row['pose'], dtype=torch.long)\n",
    "        # return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6a672307",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    # convert PIL to image\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "data = YogaDataset('dataset-annotations.csv', CURRENT_DATASET_PATH, transform=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2a6ec4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d87844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dubplate/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transforms\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mget_image_num_channels(data[\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[39m# transforms.functional.get_image_num_channels(data[1][0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[96], line 17\u001b[0m, in \u001b[0;36mYogaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[1;32m     19\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(label)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "transforms.functional.get_image_num_channels(data[1][0])\n",
    "\n",
    "# transforms.functional.get_image_num_channels(data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb0242d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transforms\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mget_image_num_channels(data[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[96], line 17\u001b[0m, in \u001b[0;36mYogaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[1;32m     19\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(label)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "transforms.functional.get_image_num_channels(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "14a9ac31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[39m0\u001b[39;49m]\n",
      "Cell \u001b[0;32mIn[96], line 17\u001b[0m, in \u001b[0;36mYogaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[1;32m     19\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(label)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "82494689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x18c6dd1d0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dbf8d350",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_features, train_labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_dataloader))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature batch shape: \u001b[39m\u001b[39m{\u001b[39;00mtrain_features\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(train_labels)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[96], line 17\u001b[0m, in \u001b[0;36mYogaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[1;32m     19\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(label)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11-dev/envs/bs-env/lib/python3.11/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(train_labels)\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35183ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(imagePaths, folder):\n",
    "    # check if the destination folder exists and if not create it\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    # loop over the image paths\n",
    "    for path in imagePaths:\n",
    "        # grab image name and its label from the path and create\n",
    "        # a placeholder corresponding to the separate label folder\n",
    "        imageName = path.split(os.path.sep)[-1]\n",
    "        label = path.split(os.path.sep)[-2]\n",
    "        labelFolder = os.path.join(folder, label)\n",
    "        # check to see if the label folder exists and if not create it\n",
    "        if not os.path.exists(labelFolder):\n",
    "          os.makedirs(labelFolder)\n",
    "        # construct the destination image path and copy the current\n",
    "        # image to it\n",
    "        destination = os.path.join(labelFolder, imageName)\n",
    "        shutil.copy(path, destination)\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(config.FLOWERS_DATASET_PATH))\n",
    "np.random.shuffle(imagePaths)\n",
    "# generate training and validation paths\n",
    "valPathsLen = int(len(imagePaths) * config.VAL_SPLIT)\n",
    "trainPathsLen = len(imagePaths) - valPathsLen\n",
    "trainPaths = imagePaths[:trainPathsLen]\n",
    "valPaths = imagePaths[trainPathsLen:]\n",
    "# copy the training and validation images to their respective\n",
    "# directories\n",
    "print(\"[INFO] copying training and validation images...\")\n",
    "copy_images(trainPaths, config.TRAIN)\n",
    "copy_images(valPaths, config.VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bedc6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train.copy()\n",
    "y_train_nn = y_train.copy()\n",
    "\n",
    "X_train_nn = torch.tensor(X_train_nn.values, dtype=torch.float64)\n",
    "# convert the numpy array from string to float\n",
    "value_counts = y_train_nn.value_counts()\n",
    "# replace values in y_train_nn with the corresponding index in value_counts\n",
    "for i in range(len(y_train_nn)):\n",
    "    y_train_nn[i] = value_counts.index.get_loc(y_train_nn[i])\n",
    "y_train_nn = torch.tensor(y_train_nn.values.astype(float), dtype=torch.float64)\n",
    "\n",
    "\n",
    "X_val_nn = val_df.copy().drop('pose', axis=1)\n",
    "X_val_nn = torch.tensor(X_val_nn.values, dtype=torch.float64)\n",
    "y_val_nn = val_df.copy()['pose']\n",
    "for i in range(len(y_val_nn)):\n",
    "    y_val_nn.iloc[i] = value_counts.index.get_loc(y_val_nn[i])\n",
    "y_val_nn = torch.tensor(y_val_nn.values.astype(float), dtype=torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "X_test_nn = test_df.copy().drop('pose', axis=1)\n",
    "X_test_nn = torch.tensor(X_test_nn.values, dtype=torch.float64)\n",
    "y_test_nn = test_df.copy()['pose']\n",
    "for i in range(len(y_test_nn)):\n",
    "    y_test_nn.iloc[i] = value_counts.index.get_loc(y_test_nn[i])\n",
    "y_test_nn = torch.tensor(y_test_nn.values.astype(float), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = YogaDataset(X_train_nn, y_train_nn)\n",
    "X_valid = YogaDataset(X_train_nn, y_train_nn)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0756b103",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got multiple values for argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m train(model, X_train_nn, y_train_nn, X_val_nn, y_val_nn, optimizer, scheduler, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m) \u001b[39m#batch_size=64, \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# train(model, X_train_nn, y_train_nn, X_val_nn, y_val_nn, criterion, optimizer, scheduler, epochs=20) #batch_size=64, \u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got multiple values for argument 'epochs'"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "model = YogaNet()\n",
    "# define the loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# train the model\n",
    "# def train(model, train_loader, val_loader, optimizer, scheduler, epochs=20):\n",
    "train(model, X_train_nn, y_train_nn, X_val_nn, y_val_nn, optimizer, scheduler, epochs=20) #batch_size=64, \n",
    "# train(model, X_train_nn, y_train_nn, X_val_nn, y_val_nn, criterion, optimizer, scheduler, epochs=20) #batch_size=64, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22beaace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom neural network class\n",
    "class YogaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(34, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x)\n",
    "\n",
    "        if self.training is not True:\n",
    "            output = self.softmax_layer(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "# create a custom function to predict the pose\n",
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "# create a custom loss function\n",
    "def custom_loss(y_pred, y_true):\n",
    "    return F.cross_entropy(y_pred, y_true)\n",
    "\n",
    "# create a custom accuracy function\n",
    "def custom_accuracy(y_pred, y_true):\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    return torch.sum(y_pred == y_true).item() / len(y_true)\n",
    "\n",
    "# create a custom function to train the model\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, epochs=20):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = custom_loss(y_pred, y)\n",
    "            acc = custom_accuracy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc\n",
    "            \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        train_acc.append(running_acc / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                y_pred = model(X)\n",
    "                loss = custom_loss(y_pred, y)\n",
    "                acc = custom_accuracy(y_pred, y)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_acc += acc\n",
    "                \n",
    "            val_loss.append(running_loss / len(val_loader))\n",
    "            val_acc.append(running_acc / len(val_loader))\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch: {epoch + 1} | Train Loss: {train_loss[-1]:.2f} | Train Acc: {train_acc[-1]:.2f} | Val Loss: {val_loss[-1]:.2f} | Val Acc: {val_acc[-1]:.2f}')\n",
    "        \n",
    "    return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "# create a custom function to test the model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    running_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X)\n",
    "            acc = custom_accuracy(y_pred, y)\n",
    "            running_acc += acc\n",
    "            \n",
    "    print(f'Test Accuracy: {running_acc / len(test_loader):.2f}')\n",
    "\n",
    "# create a custom function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), fontsize=20, horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label', fontsize=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the learning curve\n",
    "def plot_learning_curve(train_loss, val_loss, train_acc, val_acc):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(val_loss, label='validation')\n",
    "    plt.legend()\n",
    "    plt.title('Loss', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_acc, label='train')\n",
    "    plt.plot(val_acc, label='validation')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy', fontsize=20)\n",
    "    plt.xlabel('Epoch', fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the misclassified images\n",
    "def plot_misclassified_images(model, test_loader, classes):\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X)\n",
    "            predicted = torch.argmax(y_pred, dim=1)\n",
    "            wrong_predictions = torch.where(predicted != y)[0]\n",
    "            misclassified_images.append(X[wrong_predictions])\n",
    "            correct_labels.append(y[wrong_predictions])\n",
    "            predicted_labels.append(predicted[wrong_predictions])\n",
    "            \n",
    "    misclassified_images = torch.cat(misclassified_images, dim=0)\n",
    "    correct_labels = torch.cat(correct_labels, dim=0)\n",
    "    predicted_labels = torch.cat(predicted_labels, dim=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(misclassified_images[i].view(64, 64), cmap='gray')\n",
    "        plt.title(f'True Label: {classes[correct_labels[i]]} | Predicted Label: {classes[predicted_labels[i]]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the correct classified images\n",
    "def plot_correct_classified_images(model, test_loader, classes):\n",
    "    model.eval()\n",
    "    correct_classified_images = []\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X)\n",
    "            predicted = torch.argmax(y_pred, dim=1)\n",
    "            correct_predictions = torch.where(predicted == y)[0]\n",
    "            correct_classified_images.append(X[correct_predictions])\n",
    "            correct_labels.append(y[correct_predictions])\n",
    "            predicted_labels.append(predicted[correct_predictions])\n",
    "            \n",
    "    correct_classified_images = torch.cat(correct_classified_images, dim=0)\n",
    "    correct_labels = torch.cat(correct_labels, dim=0)\n",
    "    predicted_labels = torch.cat(predicted_labels, dim=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(correct_classified_images[i].view(64, 64), cmap='gray')\n",
    "        plt.title(f'True Label: {classes[correct_labels[i]]} | Predicted Label: {classes[predicted_labels[i]]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the misclassified images for a specific class\n",
    "def plot_misclassified_images_for_class(model, test_loader, classes, class_name):\n",
    "    model.eval()\n",
    "    misclassified_images = []\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X)\n",
    "            predicted = torch.argmax(y_pred, dim=1)\n",
    "            wrong_predictions = torch.where((predicted != y) & (y == classes.index(class_name)))[0]\n",
    "            misclassified_images.append(X[wrong_predictions])\n",
    "            correct_labels.append(y[wrong_predictions])\n",
    "            predicted_labels.append(predicted[wrong_predictions])\n",
    "            \n",
    "    misclassified_images = torch.cat(misclassified_images, dim=0)\n",
    "    correct_labels = torch.cat(correct_labels, dim=0)\n",
    "    predicted_labels = torch.cat(predicted_labels, dim=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(misclassified_images[i].view(64, 64), cmap='gray')\n",
    "        plt.title(f'True Label: {classes[correct_labels[i]]} | Predicted Label: {classes[predicted_labels[i]]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the correct classified images for a specific class\n",
    "def plot_correct_classified_images_for_class(model, test_loader, classes, class_name):\n",
    "    model.eval()\n",
    "    correct_classified_images = []\n",
    "    correct_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X)\n",
    "            predicted = torch.argmax(y_pred, dim=1)\n",
    "            correct_predictions = torch.where((predicted == y) & (y == classes.index(class_name)))[0]\n",
    "            correct_classified_images.append(X[correct_predictions])\n",
    "            correct_labels.append(y[correct_predictions])\n",
    "            predicted_labels.append(predicted[correct_predictions])\n",
    "            \n",
    "    correct_classified_images = torch.cat(correct_classified_images, dim=0)\n",
    "    correct_labels = torch.cat(correct_labels, dim=0)\n",
    "    predicted_labels = torch.cat(predicted_labels, dim=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(correct_classified_images[i].view(64, 64), cmap='gray')\n",
    "        plt.title(f'True Label: {classes[correct_labels[i]]} | Predicted Label: {classes[predicted_labels[i]]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the confusion matrix\n",
    "def plot_confusion_matrix(model, test_loader, classes):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_true.append(y)\n",
    "            y_pred.append(model(X))\n",
    "            \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, torch.argmax(y_pred, dim=1))\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted Label', fontsize=15)\n",
    "    plt.ylabel('True Label', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the confusion matrix for a specific class\n",
    "def plot_confusion_matrix_for_class(model, test_loader, classes, class_name):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_true.append(y)\n",
    "            y_pred.append(model(X))\n",
    "            \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, torch.argmax(y_pred, dim=1))\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted Label', fontsize=15)\n",
    "    plt.ylabel('True Label', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the accuracy for each class\n",
    "def plot_accuracy_for_each_class(model, test_loader, classes):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_true.append(y)\n",
    "            y_pred.append(model(X))\n",
    "            \n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    \n",
    "    accuracy = []\n",
    "    for i in range(len(classes)):\n",
    "        accuracy.append(accuracy_score(y_true[y_true == i], torch.argmax(y_pred, dim=1)[y_true == i]))\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.bar(classes, accuracy, color='blue')\n",
    "    plt.xlabel('Class', fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# create a custom function to plot the accuracy for a specific class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2937bcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022b446e3933469a4a223aa54716aa72305744d4ad54aaad5c7da7496274401.png_inv    34\n",
       "624f48ec0f8a222f9267f622d1e0f6af2e4afe67afeefa51d59568938588fc47.png_inv    52\n",
       "381f0c5da3370ee913a04a0a1168203439e8b41a91fe18aa2780e73f5f9e030b.png_inv    59\n",
       "aad4482cf6752e4829d4c04544a1af638cc96adb18b6a40ed23dac7122c5f39f.png_inv    16\n",
       "cb879edfa860c69f5fab921d1c0c7cd15aec6c53855919530c9bbedb1c03bb60.png        55\n",
       "                                                                            ..\n",
       "8d52bbf00c675fbbe65ada8a63a9070a7da7a4ed123cf35de20c9f7b1b4f96ca.png_inv    18\n",
       "bde37df6c21f3abe799d034a6956b13e02ef9e9b50ac40e4fa738c6237ffcdbf.png        27\n",
       "5b9c6ee42b018f9a48e265bb53132b1743e5228cce8509b5a3c57915804a8bc1.png_inv    59\n",
       "ae5d507870050d8a4f11de2d4476c3f57d2208b2e330857695dbc72fa69ddf5c.png_inv    68\n",
       "844dd9de8b49028a094199825a0bc1822c4c64906acc0b7df35f10e6469e4ca7.png_inv    54\n",
       "Name: pose, Length: 5999, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a33acb91-49a7-4d86-bd0d-4cab0825a77e",
   "metadata": {},
   "source": [
    "# TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e75b8874-2da9-4395-b9d5-a0fc3a873557",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).keypoint_names\n",
    "x_y_names = []\n",
    "for n in names:\n",
    "    x_y_names.append(n + '_x')\n",
    "    x_y_names.append(n + '_y')\n",
    "df_test = pd.DataFrame(columns=x_y_names + [\"pose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609b5f8a-242b-4002-8a87-65ab5bd2a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error with file: ./YOGA-DATASET/TEST/downdog/00000010.png. This file did not find any human to inference keypoints from. Try lowering the threshold\n",
      "There was an error with file: ./YOGA-DATASET/TEST/downdog/00000120.jpg. This file did not find any human to inference keypoints from. Try lowering the threshold\n",
      "There was an error with file: ./YOGA-DATASET/TEST/downdog/00000080.jpg. This file did not find any human to inference keypoints from. Try lowering the threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error with file: ./YOGA-DATASET/TEST/warrior2/00000039.png. This file did not find any human to inference keypoints from. Try lowering the threshold\n",
      "There was an error with file: ./YOGA-DATASET/TEST/warrior2/00000025.png. This file did not find any human to inference keypoints from. Try lowering the threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "# build keypoints dataset\n",
    "directory = \"./YOGA-DATASET/TEST/\"\n",
    "for dir in os.listdir(directory):\n",
    "    for file in os.listdir(directory + dir):\n",
    "        try:\n",
    "            keypoints_x_y = predict_keypoints_and_format(f\"{directory}{dir}/{file}\")\n",
    "            for index, n in enumerate(names):\n",
    "                df_test.loc[file, n + '_x'] = keypoints_x_y[index][0]\n",
    "                df_test.loc[file, n + '_y'] = keypoints_x_y[index][1]\n",
    "                df_test.loc[file, \"pose\"] = dir\n",
    "        except Exception as e:\n",
    "            print(f\"There was an error with file: {directory}{dir}/{file}. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2043eb43-4d73-48dd-b6eb-fd0c46b92d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('pose', axis=1)\n",
    "y_train = df['pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "953d5a4c-972a-42a7-a236-0e2d15f4e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop('pose', axis=1)\n",
    "y_test = df_test['pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3e688d0-e254-407d-9c6b-787b6dcc632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log = X_train.copy()\n",
    "X_test_log = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49dc792b-4f95-4347-b54f-1d23b6859cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 1}\n",
      "Best training score: 0.8658\n",
      "Best testing score: 0.9118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))\n",
    "])\n",
    "\n",
    "# create param grid\n",
    "params = {\n",
    "    'logreg__C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 1000000],\n",
    "}\n",
    "\n",
    "# instantiate gridsearch\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=5)\n",
    "\n",
    "# fit gridsearch\n",
    "gs.fit(X_train_log, y_train)\n",
    "\n",
    "# print best params\n",
    "print(gs.best_params_)\n",
    "print(f\"Best training score: {round(gs.best_score_, 4)}\")\n",
    "print(f\"Best testing score: {round(gs.score(X_test_log, y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728c386-f68f-44a8-b511-6cbebdaffef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
